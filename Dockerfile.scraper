# Circle of Life Scraper Dockerfile
# Optimized for Cloud Run with Playwright support

FROM python:3.11-slim

# Install system dependencies for Playwright
RUN apt-get update && apt-get install -y \
    wget \
    gnupg \
    ca-certificates \
    fonts-liberation \
    libasound2 \
    libatk-bridge2.0-0 \
    libatk1.0-0 \
    libatspi2.0-0 \
    libcups2 \
    libdbus-1-3 \
    libdrm2 \
    libgbm1 \
    libgtk-3-0 \
    libnspr4 \
    libnss3 \
    libwayland-client0 \
    libxcomposite1 \
    libxdamage1 \
    libxfixes3 \
    libxkbcommon0 \
    libxrandr2 \
    xdg-utils \
    && rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /app

# Copy requirements first for better caching
COPY requirements-scraper.txt .

# Install Python dependencies
RUN pip install --no-cache-dir -r requirements-scraper.txt

# Install Playwright and browsers
RUN pip install playwright && \
    playwright install chromium && \
    playwright install-deps chromium

# Copy application code
COPY src/scraper_cloud_run.py .
COPY src/unified_scraper.py .
COPY src/unified_scraper_enhanced.py .
COPY src/unified_scraper_simple.py .
COPY src/scraper_simple.py .
COPY src/circle_of_life.py .
COPY src/circle_of_life_scraper.py .
COPY src/forum_scraper.py .
COPY src/skidsteer_scraper.py .
COPY src/scraper_api.py .

# Set environment variables
ENV PYTHONUNBUFFERED=1
ENV GOOGLE_CLOUD_PROJECT=bobs-house-ai
ENV PORT=8080

# Run as non-root user
RUN useradd -m -u 1001 scraper && chown -R scraper:scraper /app
USER scraper

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8080/health || exit 1

# Start the unified scraper API
CMD ["python", "scraper_cloud_run.py"]
