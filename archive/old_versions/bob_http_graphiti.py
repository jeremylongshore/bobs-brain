#!/usr/bin/env python3
"""
Bob HTTP Server with Graphiti Memory
Replaces the existing Cloud Run instance with Graphiti-powered Bob
"""

import asyncio
import json
import logging
import os
from datetime import datetime

from flask import Flask, jsonify, request
from slack_sdk import WebClient
from slack_sdk.errors import SlackApiError

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Set OpenAI key if provided (will be replaced with Vertex AI later)
if not os.environ.get("OPENAI_API_KEY"):
    # Key must be provided via environment variable for security
    print("WARNING: OPENAI_API_KEY not set. Graphiti entity extraction may not work.")
    os.environ["OPENAI_API_KEY"] = "placeholder-key-required"

import vertexai

# Import Graphiti and other dependencies
from graphiti_core import Graphiti
from vertexai.generative_models import GenerativeModel

app = Flask(__name__)


class BobGraphiti:
    """Bob with Graphiti memory on Google Cloud"""

    def __init__(self):
        # Initialize Graphiti with GCP Neo4j (or local for testing)
        # Use GCP internal IP when deployed, localhost for local testing
        neo4j_uri = os.environ.get("NEO4J_URI", "bolt://10.128.0.2:7687")
        if not os.environ.get("DEPLOYED_TO_GCP"):
            # For local testing, use local Neo4j
            neo4j_uri = "bolt://localhost:7687"

        self.graphiti = Graphiti(
            uri=neo4j_uri,
            user=os.environ.get("NEO4J_USER", "neo4j"),
            password=os.environ.get("NEO4J_PASSWORD", "BobBrain2025"),
        )

        # Initialize Vertex AI for responses
        vertexai.init(project="bobs-house-ai", location="us-central1")
        self.model = GenerativeModel("gemini-1.5-flash")

        # Slack client
        self.slack_client = WebClient(token=os.environ.get("SLACK_BOT_TOKEN"))

        logger.info("âœ… Bob initialized with Graphiti memory")

    async def process_message(self, text: str, user: str, channel: str):
        """Process a message and generate response"""
        try:
            # Search for relevant context in Graphiti
            search_results = await self.graphiti.search(text, num_results=5)

            # Build context from search results
            context = ""
            if search_results:
                context = "Relevant context from memory:\n"
                for result in search_results[:3]:
                    context += f"- {str(result)[:100]}...\n"

            # Generate response with Vertex AI
            prompt = f"""You are Bob, an AI assistant for DiagnosticPro.

{context}

User: {text}
Bob (respond helpfully and concisely):"""

            response = self.model.generate_content(prompt)
            response_text = response.text

            # Store this interaction in Graphiti
            await self.graphiti.add_episode(
                name=f"conversation_{datetime.now().isoformat()}",
                episode_body=f"User {user}: {text}\nBob: {response_text}",
                source_description=f"Slack conversation in {channel}",
                reference_time=datetime.now(),
            )

            return response_text

        except Exception as e:
            logger.error(f"Error processing message: {e}")
            return "I'm having trouble accessing my memory right now. Let me try again."


# Initialize Bob
bob = BobGraphiti()


@app.route("/health", methods=["GET"])
def health():
    """Health check endpoint"""
    return jsonify(
        {
            "status": "healthy",
            "service": "Bob's Brain with Graphiti",
            "memory": "Neo4j + Graphiti",
            "ai": "Vertex AI (Gemini)",
        }
    )


@app.route("/slack/events", methods=["POST"])
def slack_events():
    """Handle Slack events"""
    try:
        # Parse the request
        slack_data = request.json

        # Handle URL verification
        if slack_data.get("type") == "url_verification":
            return jsonify({"challenge": slack_data["challenge"]})

        # Handle events
        if slack_data.get("type") == "event_callback":
            event = slack_data.get("event", {})

            # Only respond to messages (not from bots)
            if event.get("type") == "message" and not event.get("bot_id"):
                user = event.get("user")
                text = event.get("text")
                channel = event.get("channel")

                # Process asynchronously
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                response = loop.run_until_complete(bob.process_message(text, user, channel))

                # Send response to Slack
                try:
                    bob.slack_client.chat_postMessage(channel=channel, text=response)
                except SlackApiError as e:
                    logger.error(f"Slack API error: {e}")

        return jsonify({"status": "ok"})

    except Exception as e:
        logger.error(f"Error handling Slack event: {e}")
        return jsonify({"error": str(e)}), 500


@app.route("/", methods=["GET"])
def index():
    """Root endpoint"""
    return jsonify(
        {
            "service": "Bob's Brain",
            "version": "2.0",
            "features": ["Graphiti Knowledge Graph", "Neo4j Database", "Vertex AI (Gemini)", "Slack Integration"],
        }
    )


if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8080))
    app.run(host="0.0.0.0", port=port)
